{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This cell is responsible for managing imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from qiskit import Aer          # for simulator backend\n",
    "from qiskit_machine_learning.algorithms import QSVC # quantum support vector classifier class\n",
    "from qiskit_machine_learning.kernels.quantum_kernel import QuantumKernel # wraps feature map and backend combination to give to QSVC\n",
    "import qiskit.circuit.library   # for feature maps\n",
    "import numpy as np\n",
    "import joblib                   # for persistence, caching, and parallelism\n",
    "\n",
    "# for data sets and data set processing\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from qiskit_machine_learning.datasets.dataset_helper import features_and_labels_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Start by configuring joblib's caching and parallelism and the quantum backend. Parallelism and caching help save time and recover from power outages and shouldn't affect the final results. If the backend configuration is changed, the cache folder should be deleted so that the experiments run with the new backend and don't simply recall results from a previous backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# configure caching\n",
    "cache_directory = \"./joblib_cache\"\n",
    "memory = joblib.Memory(location=cache_directory, compress=False, mmap_mode=None)\n",
    "# configure parallelism\n",
    "worker_count = 6\n",
    "parallel = joblib.Parallel(n_jobs=worker_count, backend=\"loky\", batch_size=1, mmap_mode=None)\n",
    "#configure backend\n",
    "backend = Aer.get_backend(\"aer_simulator_statevector\") # should configure this to mimic IBMQ backend\n",
    "#backend.set_options(device='GPU')                      # enable GPU acceleration (comment this line to disable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The functions in this cell are responsible for loading, preparing, and splitting data sets for input to the QSVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: change this to allow specifying which classes to extract for binary classification,\n",
    "# rather than simply extracting 2 arbitrary classes. If 2 arbitrary classes are specified anyway,\n",
    "# at least make them manually selected and identifiable rather than seemingly random.\n",
    "def extract_binary_classes(feature_array, label_array):\n",
    "    \"\"\"Takes a numpy array of feature vectors and a numpy array of labels\n",
    "    and returns transformed numpy arrays with the number of classes reduced\n",
    "    to 2.\"\"\"\n",
    "    classes = list(set(label_array))[:2] # get the first 2 unique labels as classes\n",
    "    class_map = {classes[0]:0, classes[1]:1} # convert labels to 0 and 1 (needed for training step)\n",
    "    # construct a feature and label description with information from only the first 2 classes\n",
    "    features = []\n",
    "    labels = []\n",
    "    for (feature, label) in zip(feature_array, label_array):\n",
    "        if label in classes:\n",
    "            features.append(feature)\n",
    "            labels.append(label)\n",
    "    return (np.array(features), np.array(labels))\n",
    "\n",
    "def process_dataset(dataset, qubit_count=4, binary_classification=True):\n",
    "    \"\"\"Performs scaling and dimensionality reduction on all feature vectors of a data set,\n",
    "    then returns the processed vectors. It will also extract 2 classes from the data set\n",
    "    if binary_classification is True, rather than leaving the data set as a multi-class data set.\n",
    "    Some of this code is modified from the qiskit_machine_learning data set loading\n",
    "    source code (check qiskit_machine_learning.datasets.digits source code for exact location\n",
    "    of what was modified from).\"\"\"\n",
    "    feature_vectors = dataset.data\n",
    "    labels = dataset.target\n",
    "\n",
    "    # maybe extract classes for binary classification\n",
    "    if binary_classification:\n",
    "        feature_vectors, labels = extract_binary_classes(feature_vectors, labels)\n",
    "\n",
    "    # Now we standardize for gaussian around 0 with unit variance\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(feature_vectors)\n",
    "    feature_vectors = scaler.transform(feature_vectors)\n",
    "\n",
    "    # Now reduce number of features to number of qubits\n",
    "    pca = PCA(n_components=qubit_count)\n",
    "    pca.fit(feature_vectors)\n",
    "    feature_vectors = pca.transform(feature_vectors)\n",
    "\n",
    "    # Scale to the range (-1,+1)\n",
    "    minmax_scaler = MinMaxScaler((-1, 1)).fit(feature_vectors)\n",
    "    feature_vectors = minmax_scaler.transform(feature_vectors)\n",
    "\n",
    "    # perform some other transformation on the feature and label vectors\n",
    "    # as was done in the qiskit_machine_learning source code\n",
    "    dataset_dict = {label:np.array([feature_vector for feature_vector, feature_vector_label in zip(feature_vectors, labels)\n",
    "                                    if feature_vector_label == label])\n",
    "                    for label in list(set(labels))}\n",
    "    feature_vectors, labels = features_and_labels_transform(dataset_dict, labels, one_hot=False)\n",
    "\n",
    "    return feature_vectors, labels\n",
    "\n",
    "def cross_fold_sets(data, labels, k=5, seed=22):\n",
    "    \"Given a data set's feature array, yield training and testing feature arrays for k-fold validation. If the same seed is used then the same subsets should be returned across different calls.\"\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "    # for each of the k train-test splits:\n",
    "    for train_indices, test_indices in kf.split(data, labels):\n",
    "        # helper function\n",
    "        extract_elements = lambda array, indices: np.array([array[i] for i in indices])\n",
    "        # get training and testing feature vectors\n",
    "        train_features = extract_elements(data, train_indices)\n",
    "        test_features = extract_elements(data, test_indices)\n",
    "        # get training and testing labels\n",
    "        train_labels = extract_elements(labels, train_indices)\n",
    "        test_labels = extract_elements(labels, test_indices)\n",
    "        # return current split values\n",
    "        yield (train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This cell defines a function that can be given some parameters determining a classifier, like the feature map to use, the data to train on, and the backend to run the training on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MAYBE DO: make batch size a parameter\n",
    "def make_classifier(feature_map_instance, training_features, training_labels):\n",
    "    \"\"\"Given a feature map instance, training features and labels,\n",
    "    creates, trains, and returns a QSVM classifier.\"\"\"\n",
    "    # Create a quantum kernel from the feature map and\n",
    "    # backend to give to the QSVC class.\n",
    "    batch_size = 1000           # this is the QuantumKernel default\n",
    "    quantum_kernel = QuantumKernel(feature_map=feature_map_instance, batch_size=batch_size, quantum_instance=backend)\n",
    "    # Create a QSVC instance\n",
    "    qsvc = QSVC(quantum_kernel=quantum_kernel)\n",
    "    # Perform training\n",
    "    qsvc.fit(training_features, training_labels)\n",
    "    # return classifier instance\n",
    "    return qsvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This cell is similar to the above cell in that it in effect takes a specification for a classifier, but the function instead returns the generalisation metrics of the classifier that is described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: finalize what generalisation metrics should be used and calculate them (maybe also look at margin size)\n",
    "# MAYBE DO: put parameters like feature count and number of repetitions in\n",
    "# the argument list to make them independent variables of the experiments rather\n",
    "# than constants.\n",
    "# This class list is defined so that the feature map class argument to process_combination can be a number\n",
    "# instead of a class instance. This allows caching to succeed.\n",
    "feature_map_class_list = [qiskit.circuit.library.PauliFeatureMap,\n",
    "                           qiskit.circuit.library.ZFeatureMap,\n",
    "                           qiskit.circuit.library.ZZFeatureMap]\n",
    "# This function is where most of the execution time\n",
    "# lies since the model is also trained during its run time, so there\n",
    "# is a large benefit to caching it to avoid recomputation after\n",
    "# power failures. It is not a pure function however as it depends indirectly on the global\n",
    "# values of feature_map_class_list and the backend used to compute the results, so\n",
    "# the cache should be cleared if the backend or feature map list is changed.\n",
    "# NOTE: caching doesn't work properly within a python notebook since namespaces are changed,\n",
    "# so the notebook should be exported to a .py file then run if the ability to resume from\n",
    "# interruptions is important.\n",
    "@memory.cache\n",
    "def process_combination(feature_map_class_number, data_split_tuple, repetitions, qubit_count=4):\n",
    "    \"\"\"Takes a feature map class number, dataset loading function, and a backend, and\n",
    "    returns the generalisation metrics of the combination of arguments.\"\"\"\n",
    "    # Create the feature map instance.\n",
    "    feature_map_instance = feature_map_class_list[feature_map_class_number](feature_dimension=qubit_count, reps=repetitions)\n",
    "    # unpack the data split for binary classification\n",
    "    train_features, train_labels, test_features, test_labels = data_split_tuple\n",
    "\n",
    "    # create the classifier\n",
    "    qsvc = make_classifier(feature_map_instance, train_features, train_labels)\n",
    "\n",
    "    # get the classification accuracy on training and testing data as generalisation metrics\n",
    "    train_accuracy = qsvc.score(train_features, train_labels)\n",
    "    test_accuracy = qsvc.score(test_features, test_labels)\n",
    "    # return the generalisation metrics and the trained model\n",
    "    return train_accuracy, test_accuracy, qsvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This cell defines a function that collects the generalisation information of all tested classifier configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function takes a long time to run, so it benefits from parallelism.\n",
    "# It is easily parallelised by running each data set's combinations with\n",
    "# different workers.\n",
    "# MAYBE DO: separate out the classifier configurations / combinations generation into\n",
    "# a different function (for clarity). It could be called \"generate_all_combinations\"\n",
    "# or something similar\n",
    "def process_all_combinations(do_binary_classification=True):\n",
    "    \"\"\"Runs all experiments.\"\"\"\n",
    "    np.random.seed(22)     # set a fixed seed so that caching works\n",
    "    # get a list of datasets loaded into memory\n",
    "    datasets = [sklearn.datasets.load_breast_cancer(),\n",
    "                sklearn.datasets.load_digits(),\n",
    "                sklearn.datasets.load_iris(),\n",
    "                sklearn.datasets.load_wine()]\n",
    "    # corresponding human-readable names for recording results\n",
    "    dataset_names = [\"cancer\", \"digits\", \"iris\", \"wine\"]\n",
    "\n",
    "    # get a list of feature maps\n",
    "    feature_map_class_numbers = range(len(feature_map_class_list)) # feature_map_class_list is a global list defined in the previous cell\n",
    "    # corresponding human-readable names for recording results\n",
    "    feature_map_names = [\"Pauli\", \"Z\", \"ZZ\"]\n",
    "\n",
    "    # Number of qubits to use / number of features to reduce to.\n",
    "    qubit_count = 4\n",
    "\n",
    "    # Define choice of k for k-fold cross-validation. This\n",
    "    # number determines how many equally sized disjoint\n",
    "    # subsets to split the dataset into, after which each\n",
    "    # is used as the testing set in turn with the remaining\n",
    "    # subsets being used as the training set.\n",
    "    cross_validation_splits = 5 # a value of 5 gives a 20:80 test:train split, and 5 total validation splits\n",
    "    \n",
    "    # Do some output to the user to give them a sense of how long running the experiments will take\n",
    "    number_of_investigated_repetition_values = 4 # for trying depth = 2, 3, 4, and 5\n",
    "    combination_count = len(datasets) * cross_validation_splits * (number_of_investigated_repetition_values + len(feature_map_class_list)-1)\n",
    "    print(f\"Running with {len(datasets)} datasets, {len(feature_map_class_list)} feature maps, {number_of_investigated_repetition_values} different encoding repetitions for the ZZ feature map, and {cross_validation_splits}-fold cross validation, requiring the training of {combination_count} classifiers in total.\")\n",
    "\n",
    "    # create a list of each possible combination / classifier\n",
    "    # configuration so that they can be processed in parallel\n",
    "\n",
    "    ## Process each combination.\n",
    "    # First, make a list of all classifier configurations (combinations of\n",
    "    # feature maps, training and testing splits, datasets, repetitions, etc.\n",
    "    # - all identifying information for each classifier to create)\n",
    "    print(\"Generating classifier configurations...\")\n",
    "    combinations = []\n",
    "    for dataset, dataset_name in zip(datasets, dataset_names):\n",
    "        # Perform dimensionality reduction and scaling on the features,\n",
    "        # and transform the labels as done in the qiskit_machine_learning\n",
    "        # data set loading source code. Also prepares the data for\n",
    "        # binary rather than multi-class classification if enabled.\n",
    "        features, labels = process_dataset(dataset, binary_classification=do_binary_classification, qubit_count=qubit_count)\n",
    "        print(f\"{dataset_name} dataset: {len(features)} feature vectors.\")\n",
    "        # For each k-fold split of the data into training and testing sets\n",
    "        for (split_number, split_tuple) in enumerate(cross_fold_sets(features, labels, k=cross_validation_splits)):\n",
    "            # For each feature map\n",
    "            for feature_map_class_number, feature_map_name in zip(feature_map_class_numbers, feature_map_names):\n",
    "                def record_combination_with_repetitions(repetitions):\n",
    "                    print(f\"Recording combination of data set {dataset_name}, feature map {feature_map_name}, cross-validation split {split_number}, and {repetitions} encoding repetitions...\")\n",
    "                    # Record the combination in the combinations list.\n",
    "                    process_combination_args = (feature_map_class_number, split_tuple, repetitions, qubit_count)  # to be passed to process_combination\n",
    "                    identifying_key = (dataset_name, split_number, feature_map_name, repetitions)  # to identify the combination in the results dictionary\n",
    "                    combinations.append((process_combination_args, identifying_key))\n",
    "                # For ZZ feature map, try multiple encoding repetitions. For other feature maps,\n",
    "                # just do 2 repetitions.\n",
    "                if feature_map_name == \"ZZ\":\n",
    "                    for reps in range(2, 2+number_of_investigated_repetition_values):\n",
    "                        record_combination_with_repetitions(reps)\n",
    "                else:\n",
    "                    record_combination_with_repetitions(2)\n",
    "    # define a function to process the combinations information for a single classifier\n",
    "    def results_from_combination(combination):\n",
    "        # unpack the combination\n",
    "        (pc_args, identifying_key) = combination\n",
    "        # run experiment for this combination\n",
    "        results = process_combination(*pc_args)\n",
    "        # return results using human-readable names and values (other than the classifier instance, which is not human readable)\n",
    "        return (identifying_key, results)\n",
    "\n",
    "    # process each combination in parallel\n",
    "    print(\"Creating, training, and testing classifiers...\")\n",
    "    key_value_result_pairs = parallel(joblib.delayed(results_from_combination)(combination) for combination in combinations)\n",
    "    # create the results dictionary\n",
    "    results_table = {}\n",
    "    for (k, v) in key_value_result_pairs:\n",
    "        results_table[k] = v\n",
    "    return results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This cell defines a function that performs the experiments and reports their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "def main ():\n",
    "    results = process_all_combinations()\n",
    "    for combination in results:\n",
    "        train, test, model = results[combination]\n",
    "        models.append(model)\n",
    "        print(f\"Combination {combination} has train/test accuracies {train}/{test}.\")\n",
    "    joblib.dump(models, \"trained_models.cache\") # save all models to a file so they can be inspected later if desired\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This cell can be evaluated to actually perform the experiments. It can take a few hours to run so loading pre-computed results is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with 4 datasets, 3 feature maps, 4 different encoding repetitions for the ZZ feature map, and 5-fold cross validation, requiring the training of 120 classifiers in total.\n",
      "Generating classifier configurations...\n",
      "cancer dataset: 569 feature vectors.\n",
      "Recording combination of data set cancer, feature map Pauli, cross-validation split 0, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map Z, cross-validation split 0, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 0, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 0, and 3 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 0, and 4 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 0, and 5 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map Pauli, cross-validation split 1, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map Z, cross-validation split 1, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 1, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 1, and 3 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 1, and 4 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 1, and 5 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map Pauli, cross-validation split 2, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map Z, cross-validation split 2, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 2, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 2, and 3 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 2, and 4 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 2, and 5 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map Pauli, cross-validation split 3, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map Z, cross-validation split 3, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 3, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 3, and 3 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 3, and 4 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 3, and 5 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map Pauli, cross-validation split 4, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map Z, cross-validation split 4, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 4, and 2 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 4, and 3 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 4, and 4 encoding repetitions...\n",
      "Recording combination of data set cancer, feature map ZZ, cross-validation split 4, and 5 encoding repetitions...\n",
      "digits dataset: 360 feature vectors.\n",
      "Recording combination of data set digits, feature map Pauli, cross-validation split 0, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map Z, cross-validation split 0, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 0, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 0, and 3 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 0, and 4 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 0, and 5 encoding repetitions...\n",
      "Recording combination of data set digits, feature map Pauli, cross-validation split 1, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map Z, cross-validation split 1, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 1, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 1, and 3 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 1, and 4 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 1, and 5 encoding repetitions...\n",
      "Recording combination of data set digits, feature map Pauli, cross-validation split 2, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map Z, cross-validation split 2, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 2, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 2, and 3 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 2, and 4 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 2, and 5 encoding repetitions...\n",
      "Recording combination of data set digits, feature map Pauli, cross-validation split 3, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map Z, cross-validation split 3, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 3, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 3, and 3 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 3, and 4 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 3, and 5 encoding repetitions...\n",
      "Recording combination of data set digits, feature map Pauli, cross-validation split 4, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map Z, cross-validation split 4, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 4, and 2 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 4, and 3 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 4, and 4 encoding repetitions...\n",
      "Recording combination of data set digits, feature map ZZ, cross-validation split 4, and 5 encoding repetitions...\n",
      "iris dataset: 100 feature vectors.\n",
      "Recording combination of data set iris, feature map Pauli, cross-validation split 0, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map Z, cross-validation split 0, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 0, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 0, and 3 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 0, and 4 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 0, and 5 encoding repetitions...\n",
      "Recording combination of data set iris, feature map Pauli, cross-validation split 1, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map Z, cross-validation split 1, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 1, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 1, and 3 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 1, and 4 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 1, and 5 encoding repetitions...\n",
      "Recording combination of data set iris, feature map Pauli, cross-validation split 2, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map Z, cross-validation split 2, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 2, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 2, and 3 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 2, and 4 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 2, and 5 encoding repetitions...\n",
      "Recording combination of data set iris, feature map Pauli, cross-validation split 3, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map Z, cross-validation split 3, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 3, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 3, and 3 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 3, and 4 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 3, and 5 encoding repetitions...\n",
      "Recording combination of data set iris, feature map Pauli, cross-validation split 4, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map Z, cross-validation split 4, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 4, and 2 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 4, and 3 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 4, and 4 encoding repetitions...\n",
      "Recording combination of data set iris, feature map ZZ, cross-validation split 4, and 5 encoding repetitions...\n",
      "wine dataset: 130 feature vectors.\n",
      "Recording combination of data set wine, feature map Pauli, cross-validation split 0, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map Z, cross-validation split 0, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 0, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 0, and 3 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 0, and 4 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 0, and 5 encoding repetitions...\n",
      "Recording combination of data set wine, feature map Pauli, cross-validation split 1, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map Z, cross-validation split 1, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 1, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 1, and 3 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 1, and 4 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 1, and 5 encoding repetitions...\n",
      "Recording combination of data set wine, feature map Pauli, cross-validation split 2, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map Z, cross-validation split 2, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 2, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 2, and 3 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 2, and 4 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 2, and 5 encoding repetitions...\n",
      "Recording combination of data set wine, feature map Pauli, cross-validation split 3, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map Z, cross-validation split 3, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 3, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 3, and 3 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 3, and 4 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 3, and 5 encoding repetitions...\n",
      "Recording combination of data set wine, feature map Pauli, cross-validation split 4, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map Z, cross-validation split 4, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 4, and 2 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 4, and 3 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 4, and 4 encoding repetitions...\n",
      "Recording combination of data set wine, feature map ZZ, cross-validation split 4, and 5 encoding repetitions...\n",
      "Creating, training, and testing classifiers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination ('cancer', 0, 'Pauli', 2) has train/test accuracies 0.9406593406593406/0.8333333333333334.\n",
      "Combination ('cancer', 0, 'Z', 2) has train/test accuracies 0.9538461538461539/0.956140350877193.\n",
      "Combination ('cancer', 0, 'ZZ', 2) has train/test accuracies 0.9406593406593406/0.8333333333333334.\n",
      "Combination ('cancer', 0, 'ZZ', 3) has train/test accuracies 0.8945054945054945/0.7368421052631579.\n",
      "Combination ('cancer', 0, 'ZZ', 4) has train/test accuracies 0.8637362637362638/0.6929824561403509.\n",
      "Combination ('cancer', 0, 'ZZ', 5) has train/test accuracies 0.8395604395604396/0.6228070175438597.\n",
      "Combination ('cancer', 1, 'Pauli', 2) has train/test accuracies 0.9494505494505494/0.8771929824561403.\n",
      "Combination ('cancer', 1, 'Z', 2) has train/test accuracies 0.945054945054945/0.9824561403508771.\n",
      "Combination ('cancer', 1, 'ZZ', 2) has train/test accuracies 0.9494505494505494/0.8771929824561403.\n",
      "Combination ('cancer', 1, 'ZZ', 3) has train/test accuracies 0.8857142857142857/0.7894736842105263.\n",
      "Combination ('cancer', 1, 'ZZ', 4) has train/test accuracies 0.843956043956044/0.7719298245614035.\n",
      "Combination ('cancer', 1, 'ZZ', 5) has train/test accuracies 0.8285714285714286/0.7368421052631579.\n",
      "Combination ('cancer', 2, 'Pauli', 2) has train/test accuracies 0.967032967032967/0.7894736842105263.\n",
      "Combination ('cancer', 2, 'Z', 2) has train/test accuracies 0.967032967032967/0.9122807017543859.\n",
      "Combination ('cancer', 2, 'ZZ', 2) has train/test accuracies 0.967032967032967/0.7894736842105263.\n",
      "Combination ('cancer', 2, 'ZZ', 3) has train/test accuracies 0.9032967032967033/0.7280701754385965.\n",
      "Combination ('cancer', 2, 'ZZ', 4) has train/test accuracies 0.865934065934066/0.6403508771929824.\n",
      "Combination ('cancer', 2, 'ZZ', 5) has train/test accuracies 0.8417582417582418/0.631578947368421.\n",
      "Combination ('cancer', 3, 'Pauli', 2) has train/test accuracies 0.9494505494505494/0.8771929824561403.\n",
      "Combination ('cancer', 3, 'Z', 2) has train/test accuracies 0.9538461538461539/0.9473684210526315.\n",
      "Combination ('cancer', 3, 'ZZ', 2) has train/test accuracies 0.9494505494505494/0.8771929824561403.\n",
      "Combination ('cancer', 3, 'ZZ', 3) has train/test accuracies 0.8879120879120879/0.7719298245614035.\n",
      "Combination ('cancer', 3, 'ZZ', 4) has train/test accuracies 0.8505494505494505/0.7631578947368421.\n",
      "Combination ('cancer', 3, 'ZZ', 5) has train/test accuracies 0.8571428571428571/0.6491228070175439.\n",
      "Combination ('cancer', 4, 'Pauli', 2) has train/test accuracies 0.9473684210526315/0.8938053097345132.\n",
      "Combination ('cancer', 4, 'Z', 2) has train/test accuracies 0.9517543859649122/0.9469026548672567.\n",
      "Combination ('cancer', 4, 'ZZ', 2) has train/test accuracies 0.9473684210526315/0.8938053097345132.\n",
      "Combination ('cancer', 4, 'ZZ', 3) has train/test accuracies 0.8903508771929824/0.7964601769911505.\n",
      "Combination ('cancer', 4, 'ZZ', 4) has train/test accuracies 0.8442982456140351/0.7256637168141593.\n",
      "Combination ('cancer', 4, 'ZZ', 5) has train/test accuracies 0.8486842105263158/0.6548672566371682.\n",
      "Combination ('digits', 0, 'Pauli', 2) has train/test accuracies 0.9895833333333334/0.9722222222222222.\n",
      "Combination ('digits', 0, 'Z', 2) has train/test accuracies 0.9756944444444444/1.0.\n",
      "Combination ('digits', 0, 'ZZ', 2) has train/test accuracies 0.9895833333333334/0.9722222222222222.\n",
      "Combination ('digits', 0, 'ZZ', 3) has train/test accuracies 0.9409722222222222/0.8333333333333334.\n",
      "Combination ('digits', 0, 'ZZ', 4) has train/test accuracies 0.9583333333333334/0.7638888888888888.\n",
      "Combination ('digits', 0, 'ZZ', 5) has train/test accuracies 0.9166666666666666/0.7222222222222222.\n",
      "Combination ('digits', 1, 'Pauli', 2) has train/test accuracies 0.9930555555555556/0.9444444444444444.\n",
      "Combination ('digits', 1, 'Z', 2) has train/test accuracies 0.9861111111111112/0.9583333333333334.\n",
      "Combination ('digits', 1, 'ZZ', 2) has train/test accuracies 0.9930555555555556/0.9444444444444444.\n",
      "Combination ('digits', 1, 'ZZ', 3) has train/test accuracies 0.9548611111111112/0.6944444444444444.\n",
      "Combination ('digits', 1, 'ZZ', 4) has train/test accuracies 0.9305555555555556/0.7638888888888888.\n",
      "Combination ('digits', 1, 'ZZ', 5) has train/test accuracies 0.9340277777777778/0.6944444444444444.\n",
      "Combination ('digits', 2, 'Pauli', 2) has train/test accuracies 0.9861111111111112/0.9583333333333334.\n",
      "Combination ('digits', 2, 'Z', 2) has train/test accuracies 0.9826388888888888/0.9861111111111112.\n",
      "Combination ('digits', 2, 'ZZ', 2) has train/test accuracies 0.9861111111111112/0.9583333333333334.\n",
      "Combination ('digits', 2, 'ZZ', 3) has train/test accuracies 0.9444444444444444/0.7777777777777778.\n",
      "Combination ('digits', 2, 'ZZ', 4) has train/test accuracies 0.9375/0.75.\n",
      "Combination ('digits', 2, 'ZZ', 5) has train/test accuracies 0.9305555555555556/0.7777777777777778.\n",
      "Combination ('digits', 3, 'Pauli', 2) has train/test accuracies 0.9965277777777778/0.9583333333333334.\n",
      "Combination ('digits', 3, 'Z', 2) has train/test accuracies 0.9826388888888888/0.9722222222222222.\n",
      "Combination ('digits', 3, 'ZZ', 2) has train/test accuracies 0.9965277777777778/0.9583333333333334.\n",
      "Combination ('digits', 3, 'ZZ', 3) has train/test accuracies 0.9340277777777778/0.8055555555555556.\n",
      "Combination ('digits', 3, 'ZZ', 4) has train/test accuracies 0.9513888888888888/0.8055555555555556.\n",
      "Combination ('digits', 3, 'ZZ', 5) has train/test accuracies 0.9201388888888888/0.7777777777777778.\n",
      "Combination ('digits', 4, 'Pauli', 2) has train/test accuracies 0.9965277777777778/0.9583333333333334.\n",
      "Combination ('digits', 4, 'Z', 2) has train/test accuracies 0.9791666666666666/0.9861111111111112.\n",
      "Combination ('digits', 4, 'ZZ', 2) has train/test accuracies 0.9965277777777778/0.9583333333333334.\n",
      "Combination ('digits', 4, 'ZZ', 3) has train/test accuracies 0.9548611111111112/0.7777777777777778.\n",
      "Combination ('digits', 4, 'ZZ', 4) has train/test accuracies 0.9340277777777778/0.8194444444444444.\n",
      "Combination ('digits', 4, 'ZZ', 5) has train/test accuracies 0.9270833333333334/0.8055555555555556.\n",
      "Combination ('iris', 0, 'Pauli', 2) has train/test accuracies 1.0/0.7.\n",
      "Combination ('iris', 0, 'Z', 2) has train/test accuracies 0.85/0.75.\n",
      "Combination ('iris', 0, 'ZZ', 2) has train/test accuracies 1.0/0.7.\n",
      "Combination ('iris', 0, 'ZZ', 3) has train/test accuracies 0.975/0.6.\n",
      "Combination ('iris', 0, 'ZZ', 4) has train/test accuracies 0.95/0.5.\n",
      "Combination ('iris', 0, 'ZZ', 5) has train/test accuracies 0.95/0.35.\n",
      "Combination ('iris', 1, 'Pauli', 2) has train/test accuracies 0.9875/0.6.\n",
      "Combination ('iris', 1, 'Z', 2) has train/test accuracies 0.875/0.65.\n",
      "Combination ('iris', 1, 'ZZ', 2) has train/test accuracies 0.9875/0.6.\n",
      "Combination ('iris', 1, 'ZZ', 3) has train/test accuracies 0.975/0.45.\n",
      "Combination ('iris', 1, 'ZZ', 4) has train/test accuracies 0.9375/0.6.\n",
      "Combination ('iris', 1, 'ZZ', 5) has train/test accuracies 0.9625/0.55.\n",
      "Combination ('iris', 2, 'Pauli', 2) has train/test accuracies 0.9875/0.6.\n",
      "Combination ('iris', 2, 'Z', 2) has train/test accuracies 0.875/0.85.\n",
      "Combination ('iris', 2, 'ZZ', 2) has train/test accuracies 0.9875/0.6.\n",
      "Combination ('iris', 2, 'ZZ', 3) has train/test accuracies 0.975/0.45.\n",
      "Combination ('iris', 2, 'ZZ', 4) has train/test accuracies 0.9875/0.5.\n",
      "Combination ('iris', 2, 'ZZ', 5) has train/test accuracies 1.0/0.35.\n",
      "Combination ('iris', 3, 'Pauli', 2) has train/test accuracies 0.9875/0.8.\n",
      "Combination ('iris', 3, 'Z', 2) has train/test accuracies 0.9/0.75.\n",
      "Combination ('iris', 3, 'ZZ', 2) has train/test accuracies 0.9875/0.8.\n",
      "Combination ('iris', 3, 'ZZ', 3) has train/test accuracies 0.9875/0.4.\n",
      "Combination ('iris', 3, 'ZZ', 4) has train/test accuracies 0.9875/0.6.\n",
      "Combination ('iris', 3, 'ZZ', 5) has train/test accuracies 0.9875/0.4.\n",
      "Combination ('iris', 4, 'Pauli', 2) has train/test accuracies 0.975/0.8.\n",
      "Combination ('iris', 4, 'Z', 2) has train/test accuracies 0.9/0.85.\n",
      "Combination ('iris', 4, 'ZZ', 2) has train/test accuracies 0.975/0.8.\n",
      "Combination ('iris', 4, 'ZZ', 3) has train/test accuracies 0.9875/0.5.\n",
      "Combination ('iris', 4, 'ZZ', 4) has train/test accuracies 0.9625/0.55.\n",
      "Combination ('iris', 4, 'ZZ', 5) has train/test accuracies 0.9125/0.45.\n",
      "Combination ('wine', 0, 'Pauli', 2) has train/test accuracies 0.9423076923076923/0.8461538461538461.\n",
      "Combination ('wine', 0, 'Z', 2) has train/test accuracies 0.9230769230769231/0.9230769230769231.\n",
      "Combination ('wine', 0, 'ZZ', 2) has train/test accuracies 0.9423076923076923/0.8461538461538461.\n",
      "Combination ('wine', 0, 'ZZ', 3) has train/test accuracies 0.9615384615384616/0.5769230769230769.\n",
      "Combination ('wine', 0, 'ZZ', 4) has train/test accuracies 0.9711538461538461/0.6153846153846154.\n",
      "Combination ('wine', 0, 'ZZ', 5) has train/test accuracies 0.9519230769230769/0.8076923076923077.\n",
      "Combination ('wine', 1, 'Pauli', 2) has train/test accuracies 0.9711538461538461/0.7307692307692307.\n",
      "Combination ('wine', 1, 'Z', 2) has train/test accuracies 0.9326923076923077/0.9230769230769231.\n",
      "Combination ('wine', 1, 'ZZ', 2) has train/test accuracies 0.9711538461538461/0.7307692307692307.\n",
      "Combination ('wine', 1, 'ZZ', 3) has train/test accuracies 0.9230769230769231/0.5384615384615384.\n",
      "Combination ('wine', 1, 'ZZ', 4) has train/test accuracies 0.9423076923076923/0.6923076923076923.\n",
      "Combination ('wine', 1, 'ZZ', 5) has train/test accuracies 0.9326923076923077/0.6923076923076923.\n",
      "Combination ('wine', 2, 'Pauli', 2) has train/test accuracies 0.9807692307692307/0.6538461538461539.\n",
      "Combination ('wine', 2, 'Z', 2) has train/test accuracies 0.9615384615384616/0.9615384615384616.\n",
      "Combination ('wine', 2, 'ZZ', 2) has train/test accuracies 0.9807692307692307/0.6538461538461539.\n",
      "Combination ('wine', 2, 'ZZ', 3) has train/test accuracies 0.9711538461538461/0.6923076923076923.\n",
      "Combination ('wine', 2, 'ZZ', 4) has train/test accuracies 0.9519230769230769/0.6923076923076923.\n",
      "Combination ('wine', 2, 'ZZ', 5) has train/test accuracies 0.9615384615384616/0.4230769230769231.\n",
      "Combination ('wine', 3, 'Pauli', 2) has train/test accuracies 0.9807692307692307/0.7692307692307693.\n",
      "Combination ('wine', 3, 'Z', 2) has train/test accuracies 0.9423076923076923/0.9615384615384616.\n",
      "Combination ('wine', 3, 'ZZ', 2) has train/test accuracies 0.9807692307692307/0.7692307692307693.\n",
      "Combination ('wine', 3, 'ZZ', 3) has train/test accuracies 0.9423076923076923/0.6538461538461539.\n",
      "Combination ('wine', 3, 'ZZ', 4) has train/test accuracies 0.9519230769230769/0.6153846153846154.\n",
      "Combination ('wine', 3, 'ZZ', 5) has train/test accuracies 0.9423076923076923/0.46153846153846156.\n",
      "Combination ('wine', 4, 'Pauli', 2) has train/test accuracies 0.9615384615384616/0.7307692307692307.\n",
      "Combination ('wine', 4, 'Z', 2) has train/test accuracies 0.9615384615384616/0.8461538461538461.\n",
      "Combination ('wine', 4, 'ZZ', 2) has train/test accuracies 0.9615384615384616/0.7307692307692307.\n",
      "Combination ('wine', 4, 'ZZ', 3) has train/test accuracies 0.9711538461538461/0.46153846153846156.\n",
      "Combination ('wine', 4, 'ZZ', 4) has train/test accuracies 0.9423076923076923/0.6538461538461539.\n",
      "Combination ('wine', 4, 'ZZ', 5) has train/test accuracies 0.9711538461538461/0.46153846153846156.\n"
     ]
    }
   ],
   "source": [
    "#results = main()                # uncomment this when you want to run it (to prevent running accidentally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The next 3 cells should be run selectively to save and load pre-computed results. This caching is secondary to the memoization caching on individual functions, it just saves and loads the results variable only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_results():\n",
    "    \"\"\"Saves results to a file if there are any, overwriting previous results.\"\"\"\n",
    "    if results != None:\n",
    "        joblib.dump(results, \"results.cache\")\n",
    "def load_results():\n",
    "    \"\"\"Loads results from a file.\"\"\"\n",
    "    global results\n",
    "    results = joblib.load(\"results.cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save_results() # uncomment this when you want to run it (to prevent accidentally running it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load_results() # uncomment this when you want to run it (to prevent accidentally running it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "These 2 cells read the results variable and combine cross-validation runs to get statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_cross_validations():\n",
    "    def extract_cross_validations(combination):\n",
    "        \"\"\"Returns a list of training and a list of testing accuracies for the given\n",
    "        combination, using the values in the results from the different cross-validation\n",
    "        runs.\"\"\"\n",
    "        dataset_name, feature_map_name, repetitions = combination\n",
    "        train_list = []\n",
    "        test_list = []\n",
    "        for key in results:\n",
    "            (d_name, run, f_name, rep) = key\n",
    "            if d_name == dataset_name and f_name == feature_map_name and rep == repetitions:\n",
    "                train_accuracy, test_accuracy, model = results[key]\n",
    "                train_list.append(train_accuracy)\n",
    "                test_list.append(test_accuracy)\n",
    "        return train_list, test_list\n",
    "    # extract combinations to get statistics about from the results variable\n",
    "    combinations = set()\n",
    "    for key in results:\n",
    "        (d_name, run, f_name, rep) = key\n",
    "        combinations.add((d_name, f_name, rep))\n",
    "    stats = {}\n",
    "    for c in combinations:\n",
    "        train_accuracies, test_accuracies = extract_cross_validations(c)\n",
    "        stats[c] = ((np.mean(train_accuracies), np.std(train_accuracies), np.var(train_accuracies)),\n",
    "                    (np.mean(test_accuracies), np.std(test_accuracies), np.var(test_accuracies)))\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This should only run after computing or loading a value for the results variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for wine dataset, Pauli feature map, 2 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9673076923076923 | 0.7461538461538462\n",
      "Standard deviations:\n",
      "0.014390989949130531 | 0.06249260311258431\n",
      "Variances:\n",
      "0.00020710059171597596 | 0.003905325443786982\n",
      "\n",
      "Stats for wine dataset, Z feature map, 2 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9442307692307693 | 0.9230769230769231\n",
      "Standard deviations:\n",
      "0.01538461538461538 | 0.042132504423474326\n",
      "Variances:\n",
      "0.00023668639053254424 | 0.0017751479289940838\n",
      "\n",
      "Stats for wine dataset, ZZ feature map, 2 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9673076923076923 | 0.7461538461538462\n",
      "Standard deviations:\n",
      "0.014390989949130531 | 0.06249260311258431\n",
      "Variances:\n",
      "0.00020710059171597596 | 0.003905325443786982\n",
      "\n",
      "Stats for wine dataset, ZZ feature map, 3 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9538461538461538 | 0.5846153846153846\n",
      "Standard deviations:\n",
      "0.018644922528524326 | 0.08213137116947161\n",
      "Variances:\n",
      "0.000347633136094674 | 0.006745562130177514\n",
      "\n",
      "Stats for wine dataset, ZZ feature map, 4 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9519230769230769 | 0.6538461538461539\n",
      "Standard deviations:\n",
      "0.010533126105868582 | 0.03440104580768905\n",
      "Variances:\n",
      "0.00011094674556213024 | 0.0011834319526627204\n",
      "\n",
      "Stats for wine dataset, ZZ feature map, 5 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9519230769230769 | 0.5692307692307692\n",
      "Standard deviations:\n",
      "0.01359820733051053 | 0.15268794800984006\n",
      "Variances:\n",
      "0.0001849112426035503 | 0.023313609467455622\n",
      "\n",
      "Stats for cancer dataset, Pauli feature map, 2 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9507923655292077 | 0.8541996584381307\n",
      "Standard deviations:\n",
      "0.008737959335838347 | 0.03808109446036603\n",
      "Variances:\n",
      "7.635193335476453e-05 | 0.0014501697552993203\n",
      "\n",
      "Stats for cancer dataset, Z feature map, 2 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9543069211490265 | 0.9490296537804689\n",
      "Standard deviations:\n",
      "0.007134302409718124 | 0.022475147657851927\n",
      "Variances:\n",
      "5.089827087330983e-05 | 0.000505132262242247\n",
      "\n",
      "Stats for cancer dataset, ZZ feature map, 2 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9507923655292077 | 0.8541996584381307\n",
      "Standard deviations:\n",
      "0.008737959335838347 | 0.03808109446036603\n",
      "Variances:\n",
      "7.635193335476453e-05 | 0.0014501697552993203\n",
      "\n",
      "Stats for cancer dataset, ZZ feature map, 3 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.8923558897243108 | 0.7645551932929668\n",
      "Standard deviations:\n",
      "0.006200008967158313 | 0.02754057420141026\n",
      "Variances:\n",
      "3.84401111928435e-05 | 0.0007584832273433845\n",
      "\n",
      "Stats for cancer dataset, ZZ feature map, 4 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.8536948139579719 | 0.7188169538891476\n",
      "Standard deviations:\n",
      "0.009419792474876211 | 0.04828730825978787\n",
      "Variances:\n",
      "8.873249026973448e-05 | 0.002331664138975778\n",
      "\n",
      "Stats for cancer dataset, ZZ feature map, 5 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.8431434355118566 | 0.6590436267660301\n",
      "Standard deviations:\n",
      "0.009526636360837813 | 0.04058538764318259\n",
      "Variances:\n",
      "9.075680035163711e-05 | 0.0016471736901473983\n",
      "\n",
      "Stats for iris dataset, Pauli feature map, 2 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9875 | 0.7\n",
      "Standard deviations:\n",
      "0.007905694150420955 | 0.0894427190999916\n",
      "Variances:\n",
      "6.250000000000011e-05 | 0.008000000000000004\n",
      "\n",
      "Stats for iris dataset, Z feature map, 2 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.8800000000000001 | 0.77\n",
      "Standard deviations:\n",
      "0.018708286933869722 | 0.0748331477354788\n",
      "Variances:\n",
      "0.0003500000000000006 | 0.005599999999999997\n",
      "\n",
      "Stats for iris dataset, ZZ feature map, 2 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9875 | 0.7\n",
      "Standard deviations:\n",
      "0.007905694150420955 | 0.0894427190999916\n",
      "Variances:\n",
      "6.250000000000011e-05 | 0.008000000000000004\n",
      "\n",
      "Stats for iris dataset, ZZ feature map, 3 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9799999999999999 | 0.48\n",
      "Standard deviations:\n",
      "0.0061237243569579785 | 0.06782329983125267\n",
      "Variances:\n",
      "3.75000000000004e-05 | 0.004599999999999998\n",
      "\n",
      "Stats for iris dataset, ZZ feature map, 4 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9650000000000001 | 0.55\n",
      "Standard deviations:\n",
      "0.020000000000000025 | 0.04472135954999579\n",
      "Variances:\n",
      "0.00040000000000000105 | 0.001999999999999999\n",
      "\n",
      "Stats for iris dataset, ZZ feature map, 5 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9625 | 0.42000000000000004\n",
      "Standard deviations:\n",
      "0.030618621784789746 | 0.07483314773547885\n",
      "Variances:\n",
      "0.0009375000000000012 | 0.005600000000000003\n",
      "\n",
      "Stats for digits dataset, Pauli feature map, 2 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.992361111111111 | 0.9583333333333334\n",
      "Standard deviations:\n",
      "0.004049272149198111 | 0.008784104611578835\n",
      "Variances:\n",
      "1.639660493827149e-05 | 7.716049382716056e-05\n",
      "\n",
      "Stats for digits dataset, Z feature map, 2 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.98125 | 0.9805555555555557\n",
      "Standard deviations:\n",
      "0.003540985773328341 | 0.01416394309331329\n",
      "Variances:\n",
      "1.2538580246913708e-05 | 0.00020061728395061724\n",
      "\n",
      "Stats for digits dataset, ZZ feature map, 2 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.992361111111111 | 0.9583333333333334\n",
      "Standard deviations:\n",
      "0.004049272149198111 | 0.008784104611578835\n",
      "Variances:\n",
      "1.639660493827149e-05 | 7.716049382716056e-05\n",
      "\n",
      "Stats for digits dataset, ZZ feature map, 3 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9458333333333332 | 0.7777777777777777\n",
      "Standard deviations:\n",
      "0.008098544298396272 | 0.04648111258522644\n",
      "Variances:\n",
      "6.558641975308676e-05 | 0.002160493827160496\n",
      "\n",
      "Stats for digits dataset, ZZ feature map, 4 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9423611111111111 | 0.7805555555555556\n",
      "Standard deviations:\n",
      "0.010668257983150839 | 0.02693155476342406\n",
      "Variances:\n",
      "0.00011381172839506162 | 0.0007253086419753092\n",
      "\n",
      "Stats for digits dataset, ZZ feature map, 5 repetitions:\n",
      "Mean classifier accuracies:\n",
      "0.9256944444444445 | 0.7555555555555555\n",
      "Standard deviations:\n",
      "0.006440012844094266 | 0.04082482904638632\n",
      "Variances:\n",
      "4.147376543209912e-05 | 0.0016666666666666683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats = combine_cross_validations()\n",
    "# TODO: this below loop should be made more robust to experiment configuration changes if it stays in the code\n",
    "number_of_investigated_repetition_values = 4\n",
    "for dataset in (\"wine\", \"cancer\", \"iris\", \"digits\"):\n",
    "    for feature_map in (\"Pauli\", \"Z\", \"ZZ\"):\n",
    "        for repetition in range(2, (2+number_of_investigated_repetition_values) if feature_map == \"ZZ\" else 3):\n",
    "            key = (dataset, feature_map, repetition)\n",
    "            value = stats[key]\n",
    "            print(f\"Stats for {dataset} dataset, {feature_map} feature map, {repetition} repetitions:\")\n",
    "            print(\"Mean classifier accuracies:\")\n",
    "            print(f\"{value[0][0]} | {value[1][0]}\")\n",
    "            print(\"Standard deviations:\")\n",
    "            print(f\"{value[0][1]} | {value[1][1]}\")\n",
    "            print(\"Variances:\")\n",
    "            print(f\"{value[0][2]} | {value[1][2]}\")\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "C:/ProgramData/Anaconda3\\python.exe",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "name": "project.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
