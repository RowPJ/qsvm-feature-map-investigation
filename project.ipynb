{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This cell is responsible for managing imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from qiskit.providers.aer import QasmSimulator # quantum simulator class\n",
    "from qiskit_machine_learning.algorithms import QSVC # quantum support vector classifier class\n",
    "from qiskit_machine_learning.kernels.quantum_kernel import QuantumKernel # wraps feature map and backend to give to QSVC\n",
    "import qiskit_machine_learning.datasets # for data sets\n",
    "import qiskit.circuit.library           # for feature maps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The functions in this cell are responsible for loading and preparing data sets for input to the QSVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: change this to allow specifying which classes to extract for binary classification,\n",
    "# rather than simply extracting 2 arbitrary classes. If 2 arbitrary classes are specified anyway,\n",
    "# at least make them manually selected and identifiable rather than seemingly random.\n",
    "def extract_binary_classes(feature_array, label_array):\n",
    "    \"\"\"Takes a numpy array of feature vectors and a numpy array of labels\n",
    "    and returns transformed numpy arrays with the number of classes reduced\n",
    "    to 2.\"\"\"\n",
    "    classes = list(set(label_array))[:2] # get the first 2 unique labels as classes\n",
    "    class_map = {classes[0]:0, classes[1]:1} # convert labels to 0 and 1 (needed for training step)\n",
    "    # construct a feature and label description with information from only the first 2 classes\n",
    "    features = []\n",
    "    labels = []\n",
    "    for (feature, label) in zip(feature_array, label_array):\n",
    "        if label in classes:\n",
    "            features.append(feature)\n",
    "            labels.append(label)\n",
    "    return (np.array(features), np.array(labels))\n",
    "\n",
    "# MAYBE DO: make training_count and testing_count parameters\n",
    "def prepare_data_set(dataset_loader_function, feature_count=4, make_binary=True):\n",
    "    \"\"\"Given a data set loading function, loads the training and testing features and labels\n",
    "    and converts the problem to a binary classification problem.\"\"\"\n",
    "    # These variables could be parameterised to test different values or\n",
    "    # left constant here so that all experiments have the same values.\n",
    "    training_count = 10    # maximum number of training inputs to load (running time scales quadratically with this number)\n",
    "    testing_count = 20     # maximum number of testing inputs to load (running time scales linearly with this number)\n",
    "    # Note: for more information on what is happening here (and potentially how\n",
    "    # to add custom data sets), check the source code of a qiskit_machine_learning\n",
    "    # data set loading function\n",
    "    training_features, training_labels, testing_features, testing_labels = dataset_loader_function(training_count, testing_count, feature_count, one_hot=False)\n",
    "    # Convert the features and labels to a binary classification problem by removing classes\n",
    "    # and corresponding features.\n",
    "    if make_binary:\n",
    "        training_features, training_labels = extract_binary_classes(training_features, training_labels)\n",
    "        testing_features, testing_labels = extract_binary_classes(testing_features, testing_labels)\n",
    "    return (training_features, training_labels, testing_features, testing_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This cell defines a function that can be given some parameters determining a classifier, like the feature map to use, the data to train on, and the backend to run the training on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MAYBE DO: make batch size a parameter\n",
    "def make_classifier(feature_map_instance, training_features, training_labels, backend):\n",
    "    \"\"\"Given a feature map instance, training features and labels, and a quantum backend,\n",
    "    creates, trains, and returns a QSVM classifier.\"\"\"\n",
    "    # Create a quantum kernel from the feature map and\n",
    "    # backend to give to the QSVC class.\n",
    "    batch_size = 1000           # this is the QuantumKernel default\n",
    "    quantum_kernel = QuantumKernel(feature_map=feature_map_instance, batch_size=batch_size, quantum_instance=backend)\n",
    "    # Create a QSVC instance\n",
    "    qsvc = QSVC(quantum_kernel=quantum_kernel)\n",
    "    # Perform training\n",
    "    qsvc.fit(training_features, training_labels)\n",
    "    # return classifier instance\n",
    "    return qsvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This cell is similar to the above cell in that it in effect takes a specification for a classifier, but the function instead returns the generalisation metrics of the classifier that is described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: finalize what generalisation metrics should be used and calculate them\n",
    "# MAYBE DO: put parameters like feature count and  number of repetitions in\n",
    "# the argument list to make them independent variables of the experiments rather\n",
    "# than constants.\n",
    "def process_combination(feature_map_class, dataset_loader_function, backend_instance):\n",
    "    \"\"\"Takes a feature map class, dataset loading function, and a backend, and\n",
    "    returns the generalisation metrics of the combination of arguments.\"\"\"\n",
    "    # Create the feature map instance.\n",
    "    feature_count = 4\n",
    "    repetitions = 4\n",
    "    feature_map_instance = feature_map_class(feature_dimension=feature_count, reps=repetitions)\n",
    "    # load the data set for binary classification\n",
    "    train_features, train_labels, test_features, test_labels = prepare_data_set(dataset_loader_function, feature_count=feature_count, make_binary=True)\n",
    "\n",
    "    # create the classifier\n",
    "    qsvc = make_classifier(feature_map_instance, train_features, train_labels, backend_instance)\n",
    "\n",
    "    # get the classification accuracy on training and testing data as generalisation metrics\n",
    "    train_accuracy = qsvc.score(train_features, train_labels)\n",
    "    test_accuracy = qsvc.score(test_features, test_labels)\n",
    "    # return the generalisation metrics\n",
    "    return train_accuracy, test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This cell defines a function that collects the generalisation information of different possible classifier configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: maybe add ad-hoc datasets and look for other qiskit feature maps\n",
    "def main():\n",
    "    # list the datasets and feature maps to run experiments with\n",
    "    dataset_loaders = [qiskit_machine_learning.datasets.digits,\n",
    "                       qiskit_machine_learning.datasets.iris,\n",
    "                       qiskit_machine_learning.datasets.breast_cancer,\n",
    "                       qiskit_machine_learning.datasets.wine]\n",
    "    feature_map_classes = [qiskit.circuit.library.PauliFeatureMap,\n",
    "                           qiskit.circuit.library.ZFeatureMap,\n",
    "                           qiskit.circuit.library.ZZFeatureMap]\n",
    "\n",
    "    # create a quantum backend\n",
    "    backend = QasmSimulator(method=\"density_matrix\")  # should configure this to mimic IBMQ backend with QasmSimulator.from_backend(backend) method\n",
    "    # evaluate generalisation ability for each combination of feature map and data set\n",
    "    combination_count = len(dataset_loaders) * len(feature_map_classes)\n",
    "    results = {} # dictionary for storing mapping of data loader functions and feature map class pairs to classification accuracies\n",
    "    print(f\"Trying {combination_count} combinations.\")\n",
    "    for (loader_index, loader) in enumerate(dataset_loaders):\n",
    "        for (map_index, feature_map) in enumerate(feature_map_classes):\n",
    "            # TODO: do something with results like drawing graphs\n",
    "            print(f\"Data set {loader_index}, feature map {map_index}\")\n",
    "            generalisation_metrics = process_combination(feature_map, loader, backend)\n",
    "            results[(loader_index, map_index)] = generalisation_metrics\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This cell can be evaluated to actually perform the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics = main()\n",
    "for pair in metrics:\n",
    "    loader_index = pair[0]\n",
    "    map_index = pair[1]\n",
    "    train_accuracy, test_accuracy = metrics[pair]\n",
    "    print(f\"Dataset {loader_index} with feature map {map_index} has training accuracy {train_accuracy} and testing accuracy {test_accuracy}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/home/rpj/anaconda3/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
